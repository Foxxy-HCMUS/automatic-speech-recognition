{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fist we need define the video ids in the `data/video_ids.txt` file. The file should contain one video id per line. For example:\n",
    "\n",
    "```\n",
    "video_id_1\n",
    "video_id_2\n",
    "...\n",
    "video_id_n\n",
    "```\n",
    "\n",
    "This can be done by manually creating the file or by define the variable `VIDEO_SEARCH_START_DATE` in `src/config.py` file. The `VIDEO_SEARCH_START_DATE` should be in the datetime data type `datetime(YYYY, MM, DD)` and the script will search for all videos uploaded 15 days after this date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use the following command to download the video data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python src/asr/utils/collect_data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will download all the audio files from the videos in the `data/video_ids.txt` file and save them in the `data/raw/audios` folder, with the name `video_id.mp3`. The subtitles will be saved in the `data/raw/subtitles` folder with the name `video_id.vtt`. The metadata will be saved in the `data/metadata` folder with the name `video_id.json`.\n",
    "\n",
    "The metadata will contain the following information:\n",
    "- `video_id`: the video id\n",
    "- `title`: the video title\n",
    "- `description`: the video description\n",
    "- `tags`: the video tags\n",
    "- `category`: the video category\n",
    "- `duration`: the video duration\n",
    "\n",
    "The subtitles will be saved in the VTT format. The VTT format is a simple text format that contains the subtitles in the following format:\n",
    "\n",
    "```vtt\n",
    "WEBVTT\n",
    "Kind: captions\n",
    "Language: en\n",
    "\n",
    "00:00:04.376 --> 00:00:08.463\n",
    "My first job as an investor\n",
    "was when I was 24 years old,\n",
    "\n",
    "00:00:08.505 --> 00:00:12.217\n",
    "and I'm almost 50 today,\n",
    "so that is half a lifetime ago.\n",
    "\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the data we will preprocess the audio and subtitles. The subtitles will be converted to a json file, where each subtitle will be a dictionary with the following keys:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"id\": 0,\n",
    "            \"speaker\": \"A\",\n",
    "            \"text\": \" Directions, in this part, you will be asked to refer to information on the screen in order to answer three questions.\",\n",
    "            \"start\": 0,\n",
    "            \"end\": 1020 // in milliseconds\n",
    "        },\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"speaker\": \"A\",\n",
    "            \"text\": \" Directions, in this part, you will be asked to refer to information on the screen in order to answer three questions.\",\n",
    "            \"start\": 2003,\n",
    "            \"end\": 10200 // in milliseconds\n",
    "        }\n",
    "        // ....\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161 overall subtitles\n",
      "1161 without overlap subtitles\n",
      "1161 after filtering\n",
      "83 merged\n",
      "not cool \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "from asr.utils.parser import parse_subtitle\n",
    "import config as cfg\n",
    "\n",
    "subtitles = parse_subtitle(f\"{cfg.SUBTITLE_RAW_PATH}/{cfg.TWO_PEOPLE_VIDEO_ID}-en-auto.vtt\")\n",
    "with open(f\"{cfg.SUBTITLE_PROCESSED_PATH}/{cfg.TWO_PEOPLE_VIDEO_ID}.json\", \"w+\") as f:\n",
    "    json.dump(subtitles, f, indent=2, default=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_start</th>\n",
       "      <th>ts_end</th>\n",
       "      <th>original_phrase</th>\n",
       "      <th>sub_file</th>\n",
       "      <th>duration</th>\n",
       "      <th>idx</th>\n",
       "      <th>phrase</th>\n",
       "      <th>hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00.080000</td>\n",
       "      <td>00:00:14.719000</td>\n",
       "      <td>let's say that you are designing a let's say...</td>\n",
       "      <td>/space/hotel/phit/personal/asr/data/raw/subtit...</td>\n",
       "      <td>14.639</td>\n",
       "      <td>0</td>\n",
       "      <td>let's say that you are designing a</td>\n",
       "      <td>065479dc321578faf12de4c03b5082b80893134e9363c2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:14.719000</td>\n",
       "      <td>00:00:28.800000</td>\n",
       "      <td>marketplace is selling a gun how would you go ...</td>\n",
       "      <td>/space/hotel/phit/personal/asr/data/raw/subtit...</td>\n",
       "      <td>14.081</td>\n",
       "      <td>16</td>\n",
       "      <td>marketplace is selling a gun how would you go ...</td>\n",
       "      <td>d54cb81716f422937117c190414326a5bc946f56cb8912...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:28.800000</td>\n",
       "      <td>00:00:43.680000</td>\n",
       "      <td>listings what happens with those identificatio...</td>\n",
       "      <td>/space/hotel/phit/personal/asr/data/raw/subtit...</td>\n",
       "      <td>14.880</td>\n",
       "      <td>32</td>\n",
       "      <td>listings what happens with those identificatio...</td>\n",
       "      <td>02581d6c4b20027dcab817fe4fe5260753f2fd8cea1e01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:43.680000</td>\n",
       "      <td>00:00:57.360000</td>\n",
       "      <td>and then a user can flag the listing if they s...</td>\n",
       "      <td>/space/hotel/phit/personal/asr/data/raw/subtit...</td>\n",
       "      <td>13.680</td>\n",
       "      <td>44</td>\n",
       "      <td>and then a user can flag the listing if they s...</td>\n",
       "      <td>0748072ad938406083885a698ffe51336765456031604c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:57.360000</td>\n",
       "      <td>00:01:12.159000</td>\n",
       "      <td>determine it as a gun and that's the only thin...</td>\n",
       "      <td>/space/hotel/phit/personal/asr/data/raw/subtit...</td>\n",
       "      <td>14.799</td>\n",
       "      <td>58</td>\n",
       "      <td>determine it as a gun and that's the only thin...</td>\n",
       "      <td>0f925ccf7ff103e2d8dd13b28e468be09571e3992d84e9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ts_start           ts_end  \\\n",
       "0  00:00:00.080000  00:00:14.719000   \n",
       "1  00:00:14.719000  00:00:28.800000   \n",
       "2  00:00:28.800000  00:00:43.680000   \n",
       "3  00:00:43.680000  00:00:57.360000   \n",
       "4  00:00:57.360000  00:01:12.159000   \n",
       "\n",
       "                                     original_phrase  \\\n",
       "0    let's say that you are designing a let's say...   \n",
       "1  marketplace is selling a gun how would you go ...   \n",
       "2  listings what happens with those identificatio...   \n",
       "3  and then a user can flag the listing if they s...   \n",
       "4  determine it as a gun and that's the only thin...   \n",
       "\n",
       "                                            sub_file  duration  idx  \\\n",
       "0  /space/hotel/phit/personal/asr/data/raw/subtit...    14.639    0   \n",
       "1  /space/hotel/phit/personal/asr/data/raw/subtit...    14.081   16   \n",
       "2  /space/hotel/phit/personal/asr/data/raw/subtit...    14.880   32   \n",
       "3  /space/hotel/phit/personal/asr/data/raw/subtit...    13.680   44   \n",
       "4  /space/hotel/phit/personal/asr/data/raw/subtit...    14.799   58   \n",
       "\n",
       "                                              phrase  \\\n",
       "0                 let's say that you are designing a   \n",
       "1  marketplace is selling a gun how would you go ...   \n",
       "2  listings what happens with those identificatio...   \n",
       "3  and then a user can flag the listing if they s...   \n",
       "4  determine it as a gun and that's the only thin...   \n",
       "\n",
       "                                                hash  \n",
       "0  065479dc321578faf12de4c03b5082b80893134e9363c2...  \n",
       "1  d54cb81716f422937117c190414326a5bc946f56cb8912...  \n",
       "2  02581d6c4b20027dcab817fe4fe5260753f2fd8cea1e01...  \n",
       "3  0748072ad938406083885a698ffe51336765456031604c...  \n",
       "4  0f925ccf7ff103e2d8dd13b28e468be09571e3992d84e9...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(subtitles)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/m-bain/whisperX.git@78dcfaab51005aa703ee21375f81ed31bc248560\n",
    "!pip install dora-search lameenc openunmix wget Cython\n",
    "!pip install --no-build-isolation \"nemo_toolkit[asr]==1.23.0\"\n",
    "!pip install --no-deps git+https://github.com/facebookresearch/demucs#egg=demucs\n",
    "!pip install git+https://github.com/oliverguhr/deepmultilingualpunctuation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To make your changes take effect please reactivate your environment\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu116\n",
      "Collecting yt-dlp@ https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz (from -r requirements.txt (line 4))\n",
      "  Downloading https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
      "\u001b[2K     \u001b[32m/\u001b[0m \u001b[32m2.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m0m0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hObtaining file:///mnt/net/i2x256-ai03/hotel/phit/personal/asr (from -r requirements.txt (line 17))\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.31.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.31.0)\n",
      "Collecting ipykernel>=6.29.4 (from -r requirements.txt (line 3))\n",
      "  Using cached ipykernel-6.29.4-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting apiclient>=1.0.4 (from -r requirements.txt (line 5))\n",
      "  Using cached apiclient-1.0.4.tar.gz (4.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting google-api-python-client>=2.128.0 (from -r requirements.txt (line 6))\n",
      "  Using cached google_api_python_client-2.129.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: pydub>=0.25.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.25.1)\n",
      "Requirement already satisfied: transformers==4.39.3 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.39.3)\n",
      "Collecting accelerate==0.30.0 (from -r requirements.txt (line 9))\n",
      "  Using cached accelerate-0.30.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: datasets==2.19.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (2.19.1)\n",
      "Collecting mlflow==2.12.1 (from -r requirements.txt (line 11))\n",
      "  Using cached mlflow-2.12.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: levenshtein in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.25.1)\n",
      "Collecting torch==1.13.1+cu116 (from -r requirements.txt (line 13))\n",
      "  Using cached https://download.pytorch.org/whl/cu116/torch-1.13.1%2Bcu116-cp310-cp310-linux_x86_64.whl (1977.9 MB)\n",
      "Collecting torchaudio==0.13.1 (from -r requirements.txt (line 14))\n",
      "  Using cached https://download.pytorch.org/whl/cu116/torchaudio-0.13.1%2Bcu116-cp310-cp310-linux_x86_64.whl (4.2 MB)\n",
      "Collecting torchvision==0.14.1+cu116 (from -r requirements.txt (line 15))\n",
      "  Using cached https://download.pytorch.org/whl/cu116/torchvision-0.14.1%2Bcu116-cp310-cp310-linux_x86_64.whl (24.2 MB)\n",
      "Requirement already satisfied: filelock in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from transformers==4.39.3->-r requirements.txt (line 8)) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from transformers==4.39.3->-r requirements.txt (line 8)) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from transformers==4.39.3->-r requirements.txt (line 8)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from transformers==4.39.3->-r requirements.txt (line 8)) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from transformers==4.39.3->-r requirements.txt (line 8)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from transformers==4.39.3->-r requirements.txt (line 8)) (2024.5.10)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from transformers==4.39.3->-r requirements.txt (line 8)) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from transformers==4.39.3->-r requirements.txt (line 8)) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from transformers==4.39.3->-r requirements.txt (line 8)) (4.66.4)\n",
      "Requirement already satisfied: psutil in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from accelerate==0.30.0->-r requirements.txt (line 9)) (5.9.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from datasets==2.19.1->-r requirements.txt (line 10)) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from datasets==2.19.1->-r requirements.txt (line 10)) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from datasets==2.19.1->-r requirements.txt (line 10)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from datasets==2.19.1->-r requirements.txt (line 10)) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from datasets==2.19.1->-r requirements.txt (line 10)) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from datasets==2.19.1->-r requirements.txt (line 10)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1->-r requirements.txt (line 10)) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from datasets==2.19.1->-r requirements.txt (line 10)) (3.9.5)\n",
      "Collecting Flask<4 (from mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (3.0.0)\n",
      "Collecting docker<8,>=4.0.0 (from mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached docker-7.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting entrypoints<1 (from mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached entrypoints-0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (3.1.43)\n",
      "Collecting graphene<4 (from mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached graphene-3.3-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (7.1.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (3.6)\n",
      "Requirement already satisfied: matplotlib<4 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (3.8.4)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (4.25.3)\n",
      "Collecting pyarrow>=12.0.0 (from datasets==2.19.1->-r requirements.txt (line 10))\n",
      "  Using cached pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: pytz<2025 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (2024.1)\n",
      "Collecting querystring-parser<2 (from mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\n",
      "Requirement already satisfied: scikit-learn<2 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: scipy<2 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (1.13.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (2.0.30)\n",
      "Collecting sqlparse<1,>=0.4.0 (from mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached sqlparse-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from mlflow==2.12.1->-r requirements.txt (line 11)) (3.1.4)\n",
      "Collecting gunicorn<22 (from mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: typing-extensions in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from torch==1.13.1+cu116->-r requirements.txt (line 13)) (4.11.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from torchvision==0.14.1+cu116->-r requirements.txt (line 15)) (10.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 2)) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 2)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 2)) (2024.2.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (8.24.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (8.6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (1.6.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (25.1.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (6.4)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipykernel>=6.29.4->-r requirements.txt (line 3)) (5.14.3)\n",
      "Collecting brotli (from yt-dlp@ https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz->-r requirements.txt (line 4))\n",
      "  Using cached Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting mutagen (from yt-dlp@ https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz->-r requirements.txt (line 4))\n",
      "  Using cached mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pycryptodomex (from yt-dlp@ https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz->-r requirements.txt (line 4))\n",
      "  Using cached pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting websockets>=12.0 (from yt-dlp@ https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz->-r requirements.txt (line 4))\n",
      "  Using cached websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 (from google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached google_auth-2.29.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 (from google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached google_api_core-2.19.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from levenshtein->-r requirements.txt (line 12)) (3.9.0)\n",
      "Requirement already satisfied: Mako in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.12.1->-r requirements.txt (line 11)) (1.3.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from Flask<4->mlflow==2.12.1->-r requirements.txt (line 11)) (3.0.3)\n",
      "Collecting itsdangerous>=2.1.2 (from Flask<4->mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.6.2 (from Flask<4->mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached blinker-1.8.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 10)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 10)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 10)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 10)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 10)) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from aiohttp->datasets==2.19.1->-r requirements.txt (line 10)) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow==2.12.1->-r requirements.txt (line 11)) (4.0.11)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Downloading proto_plus-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached graphql_core-3.2.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting aniso8601<10,>=8 (from graphene<4->mlflow==2.12.1->-r requirements.txt (line 11))\n",
      "  Using cached aniso8601-9.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=2.128.0->-r requirements.txt (line 6)) (3.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.12.1->-r requirements.txt (line 11)) (3.17.0)\n",
      "Requirement already satisfied: decorator in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (3.0.42)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (2.18.0)\n",
      "Requirement already satisfied: stack-data in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (0.6.2)\n",
      "Requirement already satisfied: exceptiongroup in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow==2.12.1->-r requirements.txt (line 11)) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel>=6.29.4->-r requirements.txt (line 3)) (2.9.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=6.29.4->-r requirements.txt (line 3)) (4.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1->-r requirements.txt (line 11)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1->-r requirements.txt (line 11)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1->-r requirements.txt (line 11)) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.12.1->-r requirements.txt (line 11)) (1.4.5)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from pandas->datasets==2.19.1->-r requirements.txt (line 10)) (2024.1)\n",
      "Requirement already satisfied: six in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from querystring-parser<2->mlflow==2.12.1->-r requirements.txt (line 11)) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from scikit-learn<2->mlflow==2.12.1->-r requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from scikit-learn<2->mlflow==2.12.1->-r requirements.txt (line 11)) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.12.1->-r requirements.txt (line 11)) (3.0.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.12.1->-r requirements.txt (line 11)) (5.0.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (0.2.13)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.128.0->-r requirements.txt (line 6))\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel>=6.29.4->-r requirements.txt (line 3)) (0.2.2)\n",
      "Using cached accelerate-0.30.0-py3-none-any.whl (302 kB)\n",
      "Using cached mlflow-2.12.1-py3-none-any.whl (20.2 MB)\n",
      "Using cached ipykernel-6.29.4-py3-none-any.whl (117 kB)\n",
      "Downloading google_api_python_client-2.129.0-py2.py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached docker-7.0.0-py3-none-any.whl (147 kB)\n",
      "Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
      "Using cached flask-3.0.3-py3-none-any.whl (101 kB)\n",
      "Downloading google_api_core-2.19.0-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached google_auth-2.29.0-py2.py3-none-any.whl (189 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached graphene-3.3-py2.py3-none-any.whl (128 kB)\n",
      "Using cached gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Using cached sqlparse-0.5.0-py3-none-any.whl (43 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Using cached websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
      "Using cached blinker-1.8.2-py3-none-any.whl (9.5 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached googleapis_common_protos-1.63.0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
      "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading proto_plus-1.23.0-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m322.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Building wheels for collected packages: yt-dlp, apiclient, asr\n",
      "  Building wheel for yt-dlp (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for yt-dlp: filename=yt_dlp-2024.4.9-py3-none-any.whl size=2830833 sha256=27247c9ed0a0b91753712dda50a7a345e92ae787efe0368189977d407524e6a6\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9t1umf3e/wheels/4c/91/d1/c5369304e2f7afb660bb6eee093af5a7d3c0ea05a3c1e8c797\n",
      "  Building wheel for apiclient (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for apiclient: filename=apiclient-1.0.4-py3-none-any.whl size=5197 sha256=2b757024b0777388e3884bb82f0024ef99f2a6c0a6f6a2130752b642f528218e\n",
      "  Stored in directory: /mnt/net/i2x256-ai03/hotel/phit/.cache/pip/wheels/34/3d/05/8d65e9bcb2117ea3739b0fbf64d660a1cf06fa9def589ea306\n",
      "  Building editable for asr (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for asr: filename=asr-0.0.1-py3-none-any.whl size=1906 sha256=842255c0de9b4a0692660fb609238a7ef180f06974b2c9f3cc4833e3839e6181\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-9t1umf3e/wheels/2b/d6/9c/c11d8821b4b165a46950b04e8803715504b5dbfdeca97b134a\n",
      "Successfully built yt-dlp apiclient asr\n",
      "Installing collected packages: brotli, aniso8601, websockets, uritemplate, torch, sqlparse, querystring-parser, pycryptodomex, pyasn1, pyarrow, proto-plus, mutagen, itsdangerous, httplib2, gunicorn, graphql-core, googleapis-common-protos, entrypoints, cachetools, blinker, apiclient, yt-dlp, torchvision, torchaudio, rsa, pyasn1-modules, graphql-relay, Flask, docker, graphene, google-auth, accelerate, mlflow, ipykernel, google-auth-httplib2, google-api-core, google-api-python-client, asr\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0\n",
      "    Uninstalling torch-2.3.0:\n",
      "      Successfully uninstalled torch-2.3.0\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/mnt/net/i2x256-ai03/hotel/phit/miniconda3/envs/speech/lib/python3.10/site-packages/~orch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 16.0.0\n",
      "    Uninstalling pyarrow-16.0.0:\n",
      "      Successfully uninstalled pyarrow-16.0.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.3.0\n",
      "    Uninstalling torchaudio-2.3.0:\n",
      "      Successfully uninstalled torchaudio-2.3.0\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 6.29.3\n",
      "    Uninstalling ipykernel-6.29.3:\n",
      "      Successfully uninstalled ipykernel-6.29.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pyannote-audio 3.1.1 requires torch>=2.0.0, but you have torch 1.13.1+cu116 which is incompatible.\n",
      "pyannote-audio 3.1.1 requires torchaudio>=2.0.0, but you have torchaudio 0.13.1+cu116 which is incompatible.\n",
      "whisperx 3.1.1 requires torch>=2, but you have torch 1.13.1+cu116 which is incompatible.\n",
      "whisperx 3.1.1 requires torchaudio>=2, but you have torchaudio 0.13.1+cu116 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Flask-3.0.3 accelerate-0.30.0 aniso8601-9.0.1 apiclient-1.0.4 asr-0.0.1 blinker-1.8.2 brotli-1.1.0 cachetools-5.3.3 docker-7.0.0 entrypoints-0.4 google-api-core-2.19.0 google-api-python-client-2.129.0 google-auth-2.29.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.63.0 graphene-3.3 graphql-core-3.2.3 graphql-relay-3.2.0 gunicorn-21.2.0 httplib2-0.22.0 ipykernel-6.29.4 itsdangerous-2.2.0 mlflow-2.12.1 mutagen-1.47.0 proto-plus-1.23.0 pyarrow-15.0.2 pyasn1-0.6.0 pyasn1-modules-0.4.0 pycryptodomex-3.20.0 querystring-parser-1.2.4 rsa-4.9 sqlparse-0.5.0 torch-1.13.1+cu116 torchaudio-0.13.1+cu116 torchvision-0.14.1+cu116 uritemplate-4.1.1 websockets-12.0 yt-dlp-2024.4.9\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This version of torchaudio is old. SpeechBrain no longer tries using the torchaudio global backend mechanism in recipes, so if you encounter issues, update torchaudio.\n",
      "This version of torchaudio is old. SpeechBrain no longer tries using the torchaudio global backend mechanism in recipes, so if you encounter issues, update torchaudio.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wget\n",
    "from omegaconf import OmegaConf\n",
    "import json\n",
    "import shutil\n",
    "import whisperx\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "from nemo.collections.asr.models.msdd_models import NeuralDiarizer\n",
    "from deepmultilingualpunctuation import PunctuationModel\n",
    "import re\n",
    "import logging\n",
    "import nltk\n",
    "from whisperx.alignment import DEFAULT_ALIGN_MODELS_HF, DEFAULT_ALIGN_MODELS_TORCH\n",
    "from whisperx.utils import LANGUAGES, TO_LANGUAGE_CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "punct_model_langs = [\n",
    "    \"en\",\n",
    "    \"fr\",\n",
    "    \"de\",\n",
    "    \"es\",\n",
    "    \"it\",\n",
    "    \"nl\",\n",
    "    \"pt\",\n",
    "    \"bg\",\n",
    "    \"pl\",\n",
    "    \"cs\",\n",
    "    \"sk\",\n",
    "    \"sl\",\n",
    "]\n",
    "wav2vec2_langs = list(DEFAULT_ALIGN_MODELS_TORCH.keys()) + list(\n",
    "    DEFAULT_ALIGN_MODELS_HF.keys()\n",
    ")\n",
    "\n",
    "whisper_langs = sorted(LANGUAGES.keys()) + sorted(\n",
    "    [k.title() for k in TO_LANGUAGE_CODE.keys()]\n",
    ")\n",
    "\n",
    "\n",
    "def create_config(output_dir):\n",
    "    DOMAIN_TYPE = \"telephonic\"  # Can be meeting, telephonic, or general based on domain type of the audio file\n",
    "    CONFIG_FILE_NAME = f\"diar_infer_{DOMAIN_TYPE}.yaml\"\n",
    "    CONFIG_URL = f\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/{CONFIG_FILE_NAME}\"\n",
    "    MODEL_CONFIG = os.path.join(output_dir, CONFIG_FILE_NAME)\n",
    "    if not os.path.exists(MODEL_CONFIG):\n",
    "        MODEL_CONFIG = wget.download(CONFIG_URL, output_dir)\n",
    "\n",
    "    config = OmegaConf.load(MODEL_CONFIG)\n",
    "\n",
    "    data_dir = os.path.join(output_dir, \"data\")\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    meta = {\n",
    "        \"audio_filepath\": os.path.join(output_dir, \"mono_file.wav\"),\n",
    "        \"offset\": 0,\n",
    "        \"duration\": None,\n",
    "        \"label\": \"infer\",\n",
    "        \"text\": \"-\",\n",
    "        \"rttm_filepath\": None,\n",
    "        \"uem_filepath\": None,\n",
    "    }\n",
    "    with open(os.path.join(data_dir, \"input_manifest.json\"), \"w\") as fp:\n",
    "        json.dump(meta, fp)\n",
    "        fp.write(\"\\n\")\n",
    "\n",
    "    pretrained_vad = \"vad_multilingual_marblenet\"\n",
    "    pretrained_speaker_model = \"titanet_large\"\n",
    "    config.num_workers = 0  # Workaround for multiprocessing hanging with ipython issue\n",
    "    config.diarizer.manifest_filepath = os.path.join(data_dir, \"input_manifest.json\")\n",
    "    config.diarizer.out_dir = (\n",
    "        output_dir  # Directory to store intermediate files and prediction outputs\n",
    "    )\n",
    "\n",
    "    config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
    "    config.diarizer.oracle_vad = (\n",
    "        False  # compute VAD provided with model_path to vad config\n",
    "    )\n",
    "    config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
    "\n",
    "    # Here, we use our in-house pretrained NeMo VAD model\n",
    "    config.diarizer.vad.model_path = pretrained_vad\n",
    "    config.diarizer.vad.parameters.onset = 0.8\n",
    "    config.diarizer.vad.parameters.offset = 0.6\n",
    "    config.diarizer.vad.parameters.pad_offset = -0.05\n",
    "    config.diarizer.msdd_model.model_path = (\n",
    "        \"diar_msdd_telephonic\"  # Telephonic speaker diarization model\n",
    "    )\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_word_ts_anchor(s, e, option=\"start\"):\n",
    "    if option == \"end\":\n",
    "        return e\n",
    "    elif option == \"mid\":\n",
    "        return (s + e) / 2\n",
    "    return s\n",
    "\n",
    "\n",
    "def get_words_speaker_mapping(wrd_ts, spk_ts, word_anchor_option=\"start\"):\n",
    "    s, e, sp = spk_ts[0]\n",
    "    wrd_pos, turn_idx = 0, 0\n",
    "    wrd_spk_mapping = []\n",
    "    for wrd_dict in wrd_ts:\n",
    "        ws, we, wrd = (\n",
    "            int(wrd_dict[\"start\"] * 1000),\n",
    "            int(wrd_dict[\"end\"] * 1000),\n",
    "            wrd_dict[\"word\"],\n",
    "        )\n",
    "        wrd_pos = get_word_ts_anchor(ws, we, word_anchor_option)\n",
    "        while wrd_pos > float(e):\n",
    "            turn_idx += 1\n",
    "            turn_idx = min(turn_idx, len(spk_ts) - 1)\n",
    "            s, e, sp = spk_ts[turn_idx]\n",
    "            if turn_idx == len(spk_ts) - 1:\n",
    "                e = get_word_ts_anchor(ws, we, option=\"end\")\n",
    "        wrd_spk_mapping.append(\n",
    "            {\"word\": wrd, \"start_time\": ws, \"end_time\": we, \"speaker\": sp}\n",
    "        )\n",
    "    return wrd_spk_mapping\n",
    "\n",
    "\n",
    "sentence_ending_punctuations = \".?!\"\n",
    "\n",
    "\n",
    "def get_first_word_idx_of_sentence(word_idx, word_list, speaker_list, max_words):\n",
    "    is_word_sentence_end = (\n",
    "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
    "    )\n",
    "    left_idx = word_idx\n",
    "    while (\n",
    "        left_idx > 0\n",
    "        and word_idx - left_idx < max_words\n",
    "        and speaker_list[left_idx - 1] == speaker_list[left_idx]\n",
    "        and not is_word_sentence_end(left_idx - 1)\n",
    "    ):\n",
    "        left_idx -= 1\n",
    "\n",
    "    return left_idx if left_idx == 0 or is_word_sentence_end(left_idx - 1) else -1\n",
    "\n",
    "\n",
    "def get_last_word_idx_of_sentence(word_idx, word_list, max_words):\n",
    "    is_word_sentence_end = (\n",
    "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
    "    )\n",
    "    right_idx = word_idx\n",
    "    while (\n",
    "        right_idx < len(word_list)\n",
    "        and right_idx - word_idx < max_words\n",
    "        and not is_word_sentence_end(right_idx)\n",
    "    ):\n",
    "        right_idx += 1\n",
    "\n",
    "    return (\n",
    "        right_idx\n",
    "        if right_idx == len(word_list) - 1 or is_word_sentence_end(right_idx)\n",
    "        else -1\n",
    "    )\n",
    "\n",
    "\n",
    "def get_realigned_ws_mapping_with_punctuation(\n",
    "    word_speaker_mapping, max_words_in_sentence=50\n",
    "):\n",
    "    is_word_sentence_end = (\n",
    "        lambda x: x >= 0\n",
    "        and word_speaker_mapping[x][\"word\"][-1] in sentence_ending_punctuations\n",
    "    )\n",
    "    wsp_len = len(word_speaker_mapping)\n",
    "\n",
    "    words_list, speaker_list = [], []\n",
    "    for k, line_dict in enumerate(word_speaker_mapping):\n",
    "        word, speaker = line_dict[\"word\"], line_dict[\"speaker\"]\n",
    "        words_list.append(word)\n",
    "        speaker_list.append(speaker)\n",
    "\n",
    "    k = 0\n",
    "    while k < len(word_speaker_mapping):\n",
    "        line_dict = word_speaker_mapping[k]\n",
    "        if (\n",
    "            k < wsp_len - 1\n",
    "            and speaker_list[k] != speaker_list[k + 1]\n",
    "            and not is_word_sentence_end(k)\n",
    "        ):\n",
    "            left_idx = get_first_word_idx_of_sentence(\n",
    "                k, words_list, speaker_list, max_words_in_sentence\n",
    "            )\n",
    "            right_idx = (\n",
    "                get_last_word_idx_of_sentence(\n",
    "                    k, words_list, max_words_in_sentence - k + left_idx - 1\n",
    "                )\n",
    "                if left_idx > -1\n",
    "                else -1\n",
    "            )\n",
    "            if min(left_idx, right_idx) == -1:\n",
    "                k += 1\n",
    "                continue\n",
    "\n",
    "            spk_labels = speaker_list[left_idx : right_idx + 1]\n",
    "            mod_speaker = max(set(spk_labels), key=spk_labels.count)\n",
    "            if spk_labels.count(mod_speaker) < len(spk_labels) // 2:\n",
    "                k += 1\n",
    "                continue\n",
    "\n",
    "            speaker_list[left_idx : right_idx + 1] = [mod_speaker] * (\n",
    "                right_idx - left_idx + 1\n",
    "            )\n",
    "            k = right_idx\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    k, realigned_list = 0, []\n",
    "    while k < len(word_speaker_mapping):\n",
    "        line_dict = word_speaker_mapping[k].copy()\n",
    "        line_dict[\"speaker\"] = speaker_list[k]\n",
    "        realigned_list.append(line_dict)\n",
    "        k += 1\n",
    "\n",
    "    return realigned_list\n",
    "\n",
    "\n",
    "def get_sentences_speaker_mapping(word_speaker_mapping, spk_ts):\n",
    "    sentence_checker = nltk.tokenize.PunktSentenceTokenizer().text_contains_sentbreak\n",
    "    s, e, spk = spk_ts[0]\n",
    "    prev_spk = spk\n",
    "\n",
    "    snts = []\n",
    "    snt = {\"speaker\": f\"Speaker {spk}\", \"start_time\": s, \"end_time\": e, \"text\": \"\"}\n",
    "\n",
    "    for wrd_dict in word_speaker_mapping:\n",
    "        wrd, spk = wrd_dict[\"word\"], wrd_dict[\"speaker\"]\n",
    "        s, e = wrd_dict[\"start_time\"], wrd_dict[\"end_time\"]\n",
    "        if spk != prev_spk or sentence_checker(snt[\"text\"] + \" \" + wrd):\n",
    "            snts.append(snt)\n",
    "            snt = {\n",
    "                \"speaker\": f\"Speaker {spk}\",\n",
    "                \"start_time\": s,\n",
    "                \"end_time\": e,\n",
    "                \"text\": \"\",\n",
    "            }\n",
    "        else:\n",
    "            snt[\"end_time\"] = e\n",
    "        snt[\"text\"] += wrd + \" \"\n",
    "        prev_spk = spk\n",
    "\n",
    "    snts.append(snt)\n",
    "    return snts\n",
    "\n",
    "\n",
    "def get_speaker_aware_transcript(sentences_speaker_mapping, f):\n",
    "    previous_speaker = sentences_speaker_mapping[0][\"speaker\"]\n",
    "    f.write(f\"{previous_speaker}: \")\n",
    "\n",
    "    for sentence_dict in sentences_speaker_mapping:\n",
    "        speaker = sentence_dict[\"speaker\"]\n",
    "        sentence = sentence_dict[\"text\"]\n",
    "\n",
    "        # If this speaker doesn't match the previous one, start a new paragraph\n",
    "        if speaker != previous_speaker:\n",
    "            f.write(f\"\\n\\n{speaker}: \")\n",
    "            previous_speaker = speaker\n",
    "\n",
    "        # No matter what, write the current sentence\n",
    "        f.write(sentence + \" \")\n",
    "\n",
    "\n",
    "def format_timestamp(\n",
    "    milliseconds: float, always_include_hours: bool = False, decimal_marker: str = \".\"\n",
    "):\n",
    "    assert milliseconds >= 0, \"non-negative timestamp expected\"\n",
    "\n",
    "    hours = milliseconds // 3_600_000\n",
    "    milliseconds -= hours * 3_600_000\n",
    "\n",
    "    minutes = milliseconds // 60_000\n",
    "    milliseconds -= minutes * 60_000\n",
    "\n",
    "    seconds = milliseconds // 1_000\n",
    "    milliseconds -= seconds * 1_000\n",
    "\n",
    "    hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
    "    return (\n",
    "        f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def write_srt(transcript, file):\n",
    "    \"\"\"\n",
    "    Write a transcript to a file in SRT format.\n",
    "\n",
    "    \"\"\"\n",
    "    for i, segment in enumerate(transcript, start=1):\n",
    "        # write srt lines\n",
    "        print(\n",
    "            f\"{i}\\n\"\n",
    "            f\"{format_timestamp(segment['start_time'], always_include_hours=True, decimal_marker=',')} --> \"\n",
    "            f\"{format_timestamp(segment['end_time'], always_include_hours=True, decimal_marker=',')}\\n\"\n",
    "            f\"{segment['speaker']}: {segment['text'].strip().replace('-->', '->')}\\n\",\n",
    "            file=file,\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def find_numeral_symbol_tokens(tokenizer):\n",
    "    numeral_symbol_tokens = [\n",
    "        -1,\n",
    "    ]\n",
    "    for token, token_id in tokenizer.get_vocab().items():\n",
    "        has_numeral_symbol = any(c in \"0123456789%$£\" for c in token)\n",
    "        if has_numeral_symbol:\n",
    "            numeral_symbol_tokens.append(token_id)\n",
    "    return numeral_symbol_tokens\n",
    "\n",
    "\n",
    "def _get_next_start_timestamp(word_timestamps, current_word_index, final_timestamp):\n",
    "    # if current word is the last word\n",
    "    if current_word_index == len(word_timestamps) - 1:\n",
    "        return word_timestamps[current_word_index][\"start\"]\n",
    "\n",
    "    next_word_index = current_word_index + 1\n",
    "    while current_word_index < len(word_timestamps) - 1:\n",
    "        if word_timestamps[next_word_index].get(\"start\") is None:\n",
    "            # if next word doesn't have a start timestamp\n",
    "            # merge it with the current word and delete it\n",
    "            word_timestamps[current_word_index][\"word\"] += (\n",
    "                \" \" + word_timestamps[next_word_index][\"word\"]\n",
    "            )\n",
    "\n",
    "            word_timestamps[next_word_index][\"word\"] = None\n",
    "            next_word_index += 1\n",
    "            if next_word_index == len(word_timestamps):\n",
    "                return final_timestamp\n",
    "\n",
    "        else:\n",
    "            return word_timestamps[next_word_index][\"start\"]\n",
    "\n",
    "\n",
    "def filter_missing_timestamps(\n",
    "    word_timestamps, initial_timestamp=0, final_timestamp=None\n",
    "):\n",
    "    # handle the first and last word\n",
    "    if word_timestamps[0].get(\"start\") is None:\n",
    "        word_timestamps[0][\"start\"] = (\n",
    "            initial_timestamp if initial_timestamp is not None else 0\n",
    "        )\n",
    "        word_timestamps[0][\"end\"] = _get_next_start_timestamp(\n",
    "            word_timestamps, 0, final_timestamp\n",
    "        )\n",
    "\n",
    "    result = [\n",
    "        word_timestamps[0],\n",
    "    ]\n",
    "\n",
    "    for i, ws in enumerate(word_timestamps[1:], start=1):\n",
    "        # if ws doesn't have a start and end\n",
    "        # use the previous end as start and next start as end\n",
    "        if ws.get(\"start\") is None and ws.get(\"word\") is not None:\n",
    "            ws[\"start\"] = word_timestamps[i - 1][\"end\"]\n",
    "            ws[\"end\"] = _get_next_start_timestamp(word_timestamps, i, final_timestamp)\n",
    "\n",
    "        if ws[\"word\"] is not None:\n",
    "            result.append(ws)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cleanup(path: str):\n",
    "    \"\"\"path could either be relative or absolute.\"\"\"\n",
    "    # check if file or directory exists\n",
    "    if os.path.isfile(path) or os.path.islink(path):\n",
    "        # remove file\n",
    "        os.remove(path)\n",
    "    elif os.path.isdir(path):\n",
    "        # remove directory and all its content\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        raise ValueError(\"Path {} is not a file or dir.\".format(path))\n",
    "\n",
    "\n",
    "def process_language_arg(language: str, model_name: str):\n",
    "    \"\"\"\n",
    "    Process the language argument to make sure it's valid and convert language names to language codes.\n",
    "    \"\"\"\n",
    "    if language is not None:\n",
    "        language = language.lower()\n",
    "    if language not in LANGUAGES:\n",
    "        if language in TO_LANGUAGE_CODE:\n",
    "            language = TO_LANGUAGE_CODE[language]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported language: {language}\")\n",
    "\n",
    "    if model_name.endswith(\".en\") and language != \"en\":\n",
    "        if language is not None:\n",
    "            logging.warning(\n",
    "                f\"{model_name} is an English-only model but received '{language}'; using English instead.\"\n",
    "            )\n",
    "        language = \"en\"\n",
    "    return language\n",
    "\n",
    "\n",
    "def transcribe(\n",
    "    audio_file: str,\n",
    "    language: str,\n",
    "    model_name: str,\n",
    "    compute_dtype: str,\n",
    "    suppress_numerals: bool,\n",
    "    device: str,\n",
    "):\n",
    "    from faster_whisper import WhisperModel\n",
    "    from helpers import find_numeral_symbol_tokens, wav2vec2_langs\n",
    "\n",
    "    # Faster Whisper non-batched\n",
    "    # Run on GPU with FP16\n",
    "    whisper_model = WhisperModel(model_name, device=device, compute_type=compute_dtype)\n",
    "\n",
    "    # or run on GPU with INT8\n",
    "    # model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "    # or run on CPU with INT8\n",
    "    # model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "    if suppress_numerals:\n",
    "        numeral_symbol_tokens = find_numeral_symbol_tokens(whisper_model.hf_tokenizer)\n",
    "    else:\n",
    "        numeral_symbol_tokens = None\n",
    "\n",
    "    if language is not None and language in wav2vec2_langs:\n",
    "        word_timestamps = False\n",
    "    else:\n",
    "        word_timestamps = True\n",
    "\n",
    "    segments, info = whisper_model.transcribe(\n",
    "        audio_file,\n",
    "        language=language,\n",
    "        beam_size=5,\n",
    "        word_timestamps=word_timestamps,  # TODO: disable this if the language is supported by wav2vec2\n",
    "        suppress_tokens=numeral_symbol_tokens,\n",
    "        vad_filter=True,\n",
    "    )\n",
    "    whisper_results = []\n",
    "    for segment in segments:\n",
    "        whisper_results.append(segment._asdict())\n",
    "    # clear gpu vram\n",
    "    del whisper_model\n",
    "    torch.cuda.empty_cache()\n",
    "    return whisper_results, language\n",
    "\n",
    "\n",
    "def transcribe_batched(\n",
    "    audio_file: str,\n",
    "    language: str,\n",
    "    batch_size: int,\n",
    "    model_name: str,\n",
    "    compute_dtype: str,\n",
    "    suppress_numerals: bool,\n",
    "    device: str,\n",
    "):\n",
    "    import whisperx\n",
    "\n",
    "    # Faster Whisper batched\n",
    "    whisper_model = whisperx.load_model(\n",
    "        model_name,\n",
    "        device,\n",
    "        compute_type=compute_dtype,\n",
    "        asr_options={\"suppress_numerals\": suppress_numerals},\n",
    "    )\n",
    "    audio = whisperx.load_audio(audio_file)\n",
    "    result = whisper_model.transcribe(audio, language=language, batch_size=batch_size)\n",
    "    del whisper_model\n",
    "    torch.cuda.empty_cache()\n",
    "    return result[\"segments\"], result[\"language\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
